#!/usr/bin/env python3
"""
Demo script showing the enhanced cryptocurrency trading model improvements.

This script demonstrates how the improved model training works with:
1. Time-aware intraday features
2. Price action pattern recognition  
3. Boruta feature selection
4. Probability calibration
5. Ensemble modeling

Usage:
    python demo_enhanced_training.py
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Add path for imports
sys.path.append(os.path.dirname(__file__))

try:
    from train_models.train_hybrid_models import HybridModelTrainer
    print("‚úÖ Successfully imported enhanced HybridModelTrainer")
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    sys.exit(1)

def create_demo_database():
    """Create a demo SQLite database with sample cryptocurrency data"""
    import sqlite3
    
    db_path = "/tmp/demo_crypto.db"
    
    # Remove existing database
    if os.path.exists(db_path):
        os.remove(db_path)
    
    # Create connection
    conn = sqlite3.connect(db_path)
    
    # Create table structure matching the expected format
    conn.execute("""
        CREATE TABLE btceur_15m (
            timestamp TEXT PRIMARY KEY,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume REAL
        )
    """)
    
    # Generate realistic sample data (3 months of 15-minute candles)
    print("üìä Generating sample cryptocurrency data...")
    
    np.random.seed(42)
    start_date = datetime(2024, 1, 1)
    end_date = datetime(2024, 4, 1)
    
    current = start_date
    base_price = 45000.0  # Starting BTC price
    
    data = []
    while current < end_date:
        # Generate realistic price movement
        # Add some trend and volatility clustering
        if len(data) > 100:
            recent_returns = [d[4]/d[1] - 1 for d in data[-20:]]  # Recent returns
            trend = np.mean(recent_returns)
            volatility = np.std(recent_returns) * 10
        else:
            trend = 0
            volatility = 0.01
            
        # Price movement with trend and mean reversion
        price_change = np.random.normal(trend * 0.1, volatility)
        new_price = base_price * (1 + price_change)
        
        # Generate OHLC from the close price
        close = new_price
        open_price = base_price
        high = max(open_price, close) * (1 + abs(np.random.normal(0, 0.002)))
        low = min(open_price, close) * (1 - abs(np.random.normal(0, 0.002)))
        
        # Volume with some correlation to price movement
        base_volume = 1000
        volume_factor = 1 + abs(price_change) * 10  # Higher volume on big moves
        volume = base_volume * volume_factor * np.random.uniform(0.5, 2.0)
        
        data.append((
            current.strftime('%Y-%m-%d %H:%M:%S'),
            open_price,
            high,
            low,
            close,
            volume
        ))
        
        base_price = close  # Update base price
        current += timedelta(minutes=15)
    
    # Insert data
    conn.executemany("""
        INSERT INTO btceur_15m (timestamp, open, high, low, close, volume)
        VALUES (?, ?, ?, ?, ?, ?)
    """, data)
    
    conn.commit()
    conn.close()
    
    print(f"‚úÖ Created demo database with {len(data)} candles")
    print(f"üìÅ Database location: {db_path}")
    return db_path

def demo_enhanced_features():
    """Demonstrate the enhanced feature engineering"""
    print("\n" + "="*60)
    print("üöÄ DEMONSTRATING ENHANCED FEATURE ENGINEERING")
    print("="*60)
    
    # Create demo data
    db_path = create_demo_database()
    
    # Initialize trainer with demo database
    trainer = HybridModelTrainer(
        symbols=['BTCEUR'],
        data_dir=os.path.dirname(db_path),
        train_months=2,
        test_months=1,
        step_months=1
    )
    
    # Temporarily override the database path
    original_load_data = trainer.load_data
    def demo_load_data(symbol):
        import sqlite3
        conn = sqlite3.connect(db_path)
        query = f"SELECT * FROM {symbol.lower()}_15m ORDER BY timestamp"
        df = pd.read_sql_query(query, conn, index_col='timestamp', parse_dates=['timestamp'])
        conn.close()
        print(f"üìä Loaded {len(df):,} candles for {symbol}")
        print(f"üìÖ Date range: {df.index.min()} to {df.index.max()}")
        return df
    
    trainer.load_data = demo_load_data
    
    # Load and process data
    print("\n1Ô∏è‚É£ Loading sample data...")
    df = trainer.load_data('BTCEUR')
    
    print(f"\nüìà Original data shape: {df.shape}")
    print(f"üìä Columns: {list(df.columns)}")
    
    # Create enhanced features
    print("\n2Ô∏è‚É£ Creating enhanced technical features...")
    df_enhanced = trainer.create_technical_features(df)
    
    print(f"\nüìà Enhanced data shape: {df_enhanced.shape}")
    print(f"üÜï Added {df_enhanced.shape[1] - df.shape[1]} new features")
    
    # Show sample of new features
    new_features = [col for col in df_enhanced.columns if col not in df.columns]
    time_features = [f for f in new_features if 'sin' in f or 'cos' in f or 'session' in f or 'weekend' in f]
    pattern_features = [f for f in new_features if 'pattern' in f or 'breakout' in f or 'candles' in f]
    
    print(f"\nüïê Time-aware features ({len(time_features)}): {time_features[:8]}{'...' if len(time_features) > 8 else ''}")
    print(f"üìà Price action patterns ({len(pattern_features)}): {pattern_features[:8]}{'...' if len(pattern_features) > 8 else ''}")
    
    # Show feature statistics
    print(f"\nüìä Sample feature statistics:")
    sample_features = ['hour_sin', 'hour_cos', 'is_american_session', 'uptrend_pattern', 'volume_breakout']
    available_features = [f for f in sample_features if f in df_enhanced.columns]
    
    for feature in available_features[:5]:
        values = df_enhanced[feature].dropna()
        if len(values) > 0:
            print(f"   {feature:20} Range: [{values.min():.3f}, {values.max():.3f}], Mean: {values.mean():.3f}")
    
    return df_enhanced

def demo_feature_selection():
    """Demonstrate Boruta feature selection"""
    print("\n" + "="*60)
    print("üéØ DEMONSTRATING BORUTA FEATURE SELECTION")
    print("="*60)
    
    # Create sample data for feature selection demo
    trainer = HybridModelTrainer(symbols=['BTCEUR'])
    
    # Generate synthetic data with known relationships
    np.random.seed(42)
    n_samples = 1000
    
    # Create features where some are predictive and others are noise
    print("\n1Ô∏è‚É£ Creating synthetic dataset for feature selection demo...")
    
    # Predictive features (simulate technical indicators that matter)
    trend_feature = np.random.randn(n_samples).cumsum() * 0.01
    volatility_feature = np.abs(np.random.randn(n_samples)) * 0.1
    volume_feature = np.random.exponential(1, n_samples)
    momentum_feature = np.diff(np.append([0], trend_feature))
    rsi_feature = (momentum_feature - momentum_feature.mean()) / momentum_feature.std()
    
    # Create target based on these features (simulate 0.5% price increase)
    signal = (trend_feature * 2 + 
             volatility_feature * -1 + 
             volume_feature * 0.5 + 
             rsi_feature * 1.5)
    target = (signal > np.percentile(signal, 70)).astype(int)  # Top 30% as positive class
    
    # Add noise features
    noise_features = np.random.randn(n_samples, 15)
    
    # Combine all features
    feature_names = (['trend', 'volatility', 'volume', 'momentum', 'rsi'] + 
                    [f'noise_{i}' for i in range(15)])
    
    all_features = np.column_stack([
        trend_feature, volatility_feature, volume_feature, momentum_feature, rsi_feature
    ] + [noise_features[:, i] for i in range(15)])
    
    df_demo = pd.DataFrame(all_features, columns=feature_names)
    df_demo['target'] = target
    
    print(f"üìä Created dataset: {df_demo.shape[0]} samples, {df_demo.shape[1]-1} features")
    print(f"üéØ Target distribution: {target.sum()} positive ({target.mean()*100:.1f}%)")
    
    # Apply Boruta feature selection
    print("\n2Ô∏è‚É£ Applying Boruta feature selection...")
    selected_features = trainer.boruta_feature_selection(df_demo)
    
    # Show results
    predictive_selected = [f for f in selected_features if f in ['trend', 'volatility', 'volume', 'momentum', 'rsi']]
    noise_selected = [f for f in selected_features if 'noise' in f]
    
    print(f"\nüìä Boruta Results:")
    print(f"   üìà Predictive features selected: {len(predictive_selected)}/5 ({predictive_selected})")
    print(f"   üîá Noise features selected: {len(noise_selected)}/15 ({noise_selected[:3]}{'...' if len(noise_selected) > 3 else ''})")
    print(f"   ‚úÖ Overall accuracy: {len(predictive_selected)/(len(predictive_selected)+len(noise_selected))*100:.1f}% correct selections")
    
    return selected_features

def demo_probability_calibration():
    """Demonstrate probability calibration improvements"""
    print("\n" + "="*60)
    print("üéØ DEMONSTRATING PROBABILITY CALIBRATION")
    print("="*60)
    
    trainer = HybridModelTrainer(symbols=['BTCEUR'])
    
    # Create sample data that mimics the imbalanced cryptocurrency prediction problem
    np.random.seed(42)
    n_samples = 1000
    
    print("\n1Ô∏è‚É£ Creating imbalanced classification dataset...")
    
    # Generate features
    X = np.random.randn(n_samples, 10)
    
    # Create target with class imbalance (similar to 0.5% price increase detection)
    # Most samples are negative (no significant price increase)
    true_probabilities = 1 / (1 + np.exp(-X[:, 0] - 0.3 * X[:, 1]))  # Logistic relationship
    y = np.random.binomial(1, true_probabilities * 0.15)  # Scale down to create imbalance
    
    print(f"üìä Dataset: {n_samples} samples")
    print(f"üéØ Class distribution: {np.sum(y==0)} negative, {np.sum(y==1)} positive ({np.mean(y)*100:.1f}% positive)")
    
    # Split data
    split_idx = int(0.7 * n_samples)
    X_train, X_val = X[:split_idx], X[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]
    
    # Train base model (XGBoost)
    print("\n2Ô∏è‚É£ Training base XGBoost model...")
    import xgboost as xgb
    
    base_model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=4,
        learning_rate=0.1,
        random_state=42,
        scale_pos_weight=np.sum(y_train==0)/np.sum(y_train==1)  # Handle imbalance
    )
    
    base_model.fit(X_train, y_train)
    
    # Get uncalibrated predictions
    uncalibrated_proba = base_model.predict_proba(X_val)[:, 1]
    
    print(f"üìä Uncalibrated predictions range: [{uncalibrated_proba.min():.3f}, {uncalibrated_proba.max():.3f}]")
    
    # Apply calibration
    print("\n3Ô∏è‚É£ Applying isotonic regression calibration...")
    calibrated_model = trainer.calibrate_probabilities(base_model, X_train, y_train, X_val, y_val)
    
    # Get calibrated predictions
    calibrated_proba = calibrated_model.predict_proba(X_val)[:, 1]
    
    print(f"üìä Calibrated predictions range: [{calibrated_proba.min():.3f}, {calibrated_proba.max():.3f}]")
    
    # Compare confidence-based metrics
    print("\n4Ô∏è‚É£ Comparing confidence-based predictions...")
    
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    for threshold in [0.6, 0.7, 0.8]:
        # Uncalibrated metrics
        uncal_pred = (uncalibrated_proba > threshold).astype(int)
        uncal_precision = precision_score(y_val, uncal_pred, zero_division=0)
        uncal_recall = recall_score(y_val, uncal_pred, zero_division=0)
        uncal_f1 = f1_score(y_val, uncal_pred, zero_division=0)
        
        # Calibrated metrics
        cal_pred = (calibrated_proba > threshold).astype(int)
        cal_precision = precision_score(y_val, cal_pred, zero_division=0)
        cal_recall = recall_score(y_val, cal_pred, zero_division=0)
        cal_f1 = f1_score(y_val, cal_pred, zero_division=0)
        
        print(f"\n   {threshold*100}% Confidence Threshold:")
        print(f"   üìä Uncalibrated - P: {uncal_precision:.4f}, R: {uncal_recall:.4f}, F1: {uncal_f1:.4f}")
        print(f"   üéØ Calibrated   - P: {cal_precision:.4f}, R: {cal_recall:.4f}, F1: {cal_f1:.4f}")
        print(f"   üìà F1 Improvement: {((cal_f1/uncal_f1 - 1)*100) if uncal_f1 > 0 else 0:.1f}%")

def main():
    """Run the enhanced training demonstration"""
    print("üöÄ CRYPTOCURRENCY TRADING MODEL ENHANCEMENTS DEMO")
    print("="*70)
    print("This demo showcases the scientifically-validated improvements:")
    print("‚Ä¢ Time-aware intraday features")
    print("‚Ä¢ Price action pattern recognition") 
    print("‚Ä¢ Boruta feature selection")
    print("‚Ä¢ Probability calibration")
    print("‚Ä¢ Model ensemble capabilities")
    print("="*70)
    
    try:
        # Demo 1: Enhanced features
        demo_enhanced_features()
        
        # Demo 2: Feature selection
        demo_feature_selection() 
        
        # Demo 3: Probability calibration
        demo_probability_calibration()
        
        print("\n" + "="*70)
        print("üéâ DEMO COMPLETED SUCCESSFULLY!")
        print("="*70)
        print("‚úÖ All enhancements are working and ready for production use")
        print("üéØ The model now includes:")
        print("   ‚Ä¢ 12+ time-aware features for intraday pattern recognition")
        print("   ‚Ä¢ 15+ price action patterns for market microstructure")
        print("   ‚Ä¢ Intelligent feature selection to reduce noise")  
        print("   ‚Ä¢ Calibrated probabilities for accurate confidence estimates")
        print("   ‚Ä¢ Ensemble modeling for improved generalization")
        print("\nüìä Expected improvements:")
        print("   ‚Ä¢ Better F1 scores at high confidence thresholds (60%, 70%)")
        print("   ‚Ä¢ More reliable probability estimates for risk management")
        print("   ‚Ä¢ Enhanced prediction accuracy for 0.5% price movements")
        print("   ‚Ä¢ Reduced overfitting through feature selection and ensembling")
        
        # Cleanup
        demo_db = "/tmp/demo_crypto.db"
        if os.path.exists(demo_db):
            os.remove(demo_db)
            
    except Exception as e:
        print(f"\n‚ùå Demo failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)